{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73ef31a9",
   "metadata": {},
   "source": [
    "# Классическое компьютерное зрение, практическая работа\n",
    "\n",
    "Этот ноутбук содержит примеры работы с библиотекой OpenCV. Он посвящен цветовым пространствам, а также построению и анализу бинарных масок объектов.\n",
    "\n",
    "**Примечание для преподавателей.**\n",
    "\n",
    "Задания приведены с решениями, их стоит предварительно удалять, а потом заниматься написанием кода вместе с учениками. Если что-то не получается, лучше сначала всем посоветоваться, потом погуглить, а если ничего из этого не помогло, нужно обращаться к этому ноутбуку."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f509726c",
   "metadata": {},
   "source": [
    "## Часть 1: распределения\n",
    "\n",
    "Обратите внимание на изменения, внесенные в код.\n",
    "\n",
    "Теперь при изменении значения трекбара новое значение не будет распечатываться.\n",
    "\n",
    "\n",
    "**Задание 1:** добавьте в программу возможность останавливать считывание новых кадров по нажатию пробела (функцию паузы воспроизведения). Чтобы сделать это, нужно во-первых узнать код клавиши \"пробел\" (можно распечатать *key*), во-вторых завести булевую переменную (флаг) того, нужно ли считывать новые кадры, и в-третьих завести переменную для кадра, в которой он будет храниться, пока считывание новых не производится.\n",
    "\n",
    "**Задание 2:** замените прибавление значения *val* ко всем каналам всех пикселей на прибавление только к нулевому каналу. Как меняются цвета при изменении положения трекбара? Попробуйте прибавлять его значение ко второму каналу, к третьему. В *OpenCV* по умолчанию используется порядок цветов *RGB* или *BGR*?\n",
    "\n",
    "**Задание 3:** уменьшите вдвое размеры кадра с помощью функции *cv2.resize* перед построением распределения. Обратите внимание на изменение скорости работы программы.\n",
    "\n",
    "**Задание 4:** добавьте выведение распределений яркостей в двух других каналах. Разберитесь с использованием функции *np.concatenate*, объединяющей несколько массивов в один, и выведите кадры видео и распределения в одно окно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce04eb0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading failed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def print_val(val):\n",
    "    print(val)\n",
    "\n",
    "def nothing(val):\n",
    "    pass\n",
    "\n",
    "#функция построения и рисования распределения\n",
    "def plot_dist(channel):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(channel.ravel(), 25, [0,256])\n",
    "    \n",
    "    fig.canvas.draw()\n",
    "    dist = np.array(fig.canvas.renderer.buffer_rgba())\n",
    "    plt.close()\n",
    "    \n",
    "    return dist\n",
    "\n",
    "cv2.namedWindow(\"frame\")\n",
    "\n",
    "cv2.createTrackbar(\"value\", \"frame\", 20, 200, nothing)\n",
    "\n",
    "video_name = \"unicycle.mp4\"\n",
    "\n",
    "cam = cv2.VideoCapture(video_name)\n",
    "\n",
    "skip_frame_reading = False\n",
    "\n",
    "success, frame_ = cam.read()\n",
    "\n",
    "while(True):\n",
    "    if (skip_frame_reading == False):\n",
    "        success, frame_ = cam.read()\n",
    "    \n",
    "    if (success == False):\n",
    "        print(\"reading failed\")\n",
    "        \n",
    "        cam.release()\n",
    "\n",
    "        cam = cv2.VideoCapture(video_name)\n",
    "        \n",
    "        continue\n",
    "    \n",
    "    w, h, _ = frame_.shape\n",
    "    \n",
    "    frame = cv2.resize(frame_, (h // 2, w // 2))\n",
    "    \n",
    "    val = cv2.getTrackbarPos(\"value\", \"frame\")\n",
    "    \n",
    "    frame[:, :, 0] += np.uint8(val)\n",
    "    \n",
    "    #########################\n",
    "    # будет построено распределение яркостей в нулевом канале,\n",
    "    # то есть frame[:, :, 0]\n",
    "    \n",
    "    dist_0 = plot_dist(frame[:, :, 0])\n",
    "    dist_1 = plot_dist(frame[:, :, 1])\n",
    "    dist_2 = plot_dist(frame[:, :, 2])\n",
    "\n",
    "    dists = np.concatenate((dist_0, dist_1, dist_2), axis=1)\n",
    "        \n",
    "    wd, hd, _ = dists.shape\n",
    "    \n",
    "    dists_resized = cv2.resize(dists, (h // 2, int(w // 2 * h // 2 / hd)))\n",
    "    \n",
    "    #обратите внимание, что число каналов в изображении в графиками\n",
    "    #равно четырем, и его нажно сократить до 3, чтобы\n",
    "    #сконкатенировать с кадром\n",
    "    result = np.concatenate((frame, dists_resized[:, :, :3]), axis=0)\n",
    "    \n",
    "    cv2.imshow(\"frame\", result)\n",
    "\n",
    "    #########################\n",
    "\n",
    "    key = cv2.waitKey(240) & 0xFF\n",
    "        \n",
    "    if (key == ord('q')):\n",
    "        break\n",
    "    \n",
    "    if (key == 32):\n",
    "        skip_frame_reading = not skip_frame_reading\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a832634",
   "metadata": {},
   "source": [
    "## Часть 2: цветовые пространства\n",
    "\n",
    "**Задание 5:** добавьте перевод изображения в цветовое пространство *HSV* до прибавления значения трекбара и обратный перевод после. Как изменяются распределения (которые нужно строить по *RGB* изображению после обратного перевода) при изменении *H*, *S*, *V*?\n",
    "\n",
    "**Задание 6:** избавьтесь от переполнений, заменив операцию с прибавлением числа на использование функции *cv2.add*. Установите 100 значением по умолчанию для трекбара и добавьте вычитание 100 после считывания, чтобы программа выводила видео без изменений сразу после запуска. Постарайтесь понять, какие изменения происходят с кадрами видео и почему при прибавлении значения к разным каналам. Попробуйте добиться видимости дневного освещения с помощью манипуляций в *HSV*. Попробуйте сделать видео серым.\n",
    "\n",
    "**Задание 7:** попробуйте уменьшать изображение с помощью *cv2.resize* или задания шага в обращении к массивам (*array[::k]*). Засеките время построения одного распределения и время одного прохода цикла с помощью библиотеки *time*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02f7141e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading failed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def nothing(val):\n",
    "    pass\n",
    "\n",
    "#функция построения и рисования распределения\n",
    "def plot_dist(channel):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(channel.ravel(), 25, [0,256])\n",
    "    \n",
    "    fig.canvas.draw()\n",
    "    dist = np.array(fig.canvas.renderer.buffer_rgba())\n",
    "    plt.close()\n",
    "    \n",
    "    return dist\n",
    "\n",
    "cv2.namedWindow(\"frame\")\n",
    "\n",
    "cv2.createTrackbar(\"value\", \"frame\", 100, 255, nothing)\n",
    "\n",
    "video_name = \"unicycle.mp4\"\n",
    "\n",
    "cam = cv2.VideoCapture(video_name)\n",
    "\n",
    "skip_frame_reading = False\n",
    "\n",
    "success, frame_ = cam.read()\n",
    "\n",
    "#out = cv2.VideoWriter('board_corners.avi',\n",
    "#        cv2.VideoWriter_fourcc('M','J','P','G'), 20, (1920, 1080))\n",
    "\n",
    "while(True):\n",
    "    if (skip_frame_reading == False):\n",
    "        success, frame_ = cam.read()\n",
    "    \n",
    "    if (success == False):\n",
    "        print(\"reading failed\")\n",
    "        \n",
    "        cam.release()\n",
    "\n",
    "        cam = cv2.VideoCapture(video_name)\n",
    "        \n",
    "        continue\n",
    "    \n",
    "    w, h, _ = frame_.shape\n",
    "    \n",
    "    frame = cv2.resize(frame_, (h, w))\n",
    "    \n",
    "    val = cv2.getTrackbarPos(\"value\", \"frame\")\n",
    "    \n",
    "    frame_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    #frame_hsv[:, :, 1] += np.uint8(val - 100)\n",
    "    \n",
    "    frame_hsv[:, :, 2] = cv2.add(frame_hsv[:, :, 2], val - 100)\n",
    "    \n",
    "    frame = cv2.cvtColor(frame_hsv, cv2.COLOR_HSV2BGR)\n",
    "        \n",
    "    dist_0 = plot_dist(frame[::10, ::10, 0])\n",
    "    dist_1 = plot_dist(frame[::10, ::10, 1])\n",
    "    dist_2 = plot_dist(frame[::10, ::10, 2])\n",
    "\n",
    "    dists = np.concatenate((dist_0, dist_1, dist_2), axis=1)\n",
    "        \n",
    "    wd, hd, _ = dists.shape\n",
    "    \n",
    "    dists_resized = cv2.resize(dists, (h, 2 * int(w // 2 * h // 2 / hd)))\n",
    "    \n",
    "    result = np.concatenate((frame, dists_resized[:, :, :3]), axis=0)\n",
    "        \n",
    "    #frame[:, :, 1] += (255 - dst) // 3\n",
    "    \n",
    "    #cv2.imshow(\"asca\", 255 - dst)\n",
    "    \n",
    "    cv2.imshow(\"frame\", result)\n",
    "    \n",
    "    #out.write(cv2.cvtColor(255 - dst, cv2.COLOR_GRAY2RGB))\n",
    "    \n",
    "    key = cv2.waitKey(240) & 0xFF\n",
    "        \n",
    "    if (key == ord('q')):\n",
    "        break\n",
    "    \n",
    "    if (key == 32):\n",
    "        skip_frame_reading = not skip_frame_reading\n",
    "\n",
    "out.release()\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33b53fa",
   "metadata": {},
   "source": [
    "## Часть 3: работа с  масками\n",
    "\n",
    "Можно ли выделить выделить все объекты вместе, при этом не выделяя фон? Возможно это или нет? Попробуйте это сделать.\n",
    "\n",
    "У разных объектов цвет отличается, и их все нельзя выделить внутри области в пространстве *HSV*, в которой не находился бы фон. Поэтому вместо того, чтобы выделять объекты, выделим фон, а потом инвертируем маску.\n",
    "\n",
    "**Задание 8:** уменьшите размер изображения, чтобы оно вместе с маской влезало на экран.\n",
    "\n",
    "**Задание 9:** добавьте печать текущих порогов (со стиранием старых). Выведите маску и исходное изображение в одном окне, настройте цветовой фильтр на фон и измените у трекбаров значения по умолчанию.\n",
    "\n",
    "**Задание 10:** инвертируйте маску, чтобы объекты отображались на ней в виде белых областей.\n",
    "\n",
    "**Задание 11:** примените сглаживающий фильтр (*cv2.blur*). Добавьте трекбар для размера ядра фильтра, подойдут значения от *1* (без сглаживания) до достаточно больших, порядка нескольких десятков. Отследите, как изменяется качество выделения объектов при применени сглаживания разной интенсивности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f983bc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 14 78 25 80 185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def nothing(val):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow(\"frame\")\n",
    "\n",
    "cv2.createTrackbar(\"lb\", \"frame\",   7, 255, nothing)\n",
    "cv2.createTrackbar(\"lg\", \"frame\",  14, 255, nothing)\n",
    "cv2.createTrackbar(\"lr\", \"frame\",  78, 255, nothing)\n",
    "cv2.createTrackbar(\"hb\", \"frame\",  25, 255, nothing)\n",
    "cv2.createTrackbar(\"hg\", \"frame\",  80, 255, nothing)\n",
    "cv2.createTrackbar(\"hr\", \"frame\", 185, 255, nothing)\n",
    "cv2.createTrackbar(\"ksz\", \"frame\", 0, 20, nothing)\n",
    "\n",
    "img = cv2.imread(\"objects.jpg\")\n",
    "\n",
    "while(True):\n",
    "    frame_ = copy.deepcopy(img)\n",
    "    \n",
    "    w, h, _ = frame_.shape\n",
    "    \n",
    "    frame = cv2.resize(frame_, (h // 4, w // 4))\n",
    "\n",
    "    ksz = cv2.getTrackbarPos(\"ksz\", \"frame\") + 1\n",
    "    frame = cv2.blur(frame, (ksz, ksz))\n",
    "    \n",
    "    lb = cv2.getTrackbarPos(\"lb\", \"frame\")\n",
    "    lg = cv2.getTrackbarPos(\"lg\", \"frame\")\n",
    "    lr = cv2.getTrackbarPos(\"lr\", \"frame\")\n",
    "    hb = cv2.getTrackbarPos(\"hb\", \"frame\")\n",
    "    hg = cv2.getTrackbarPos(\"hg\", \"frame\")\n",
    "    hr = cv2.getTrackbarPos(\"hr\", \"frame\")\n",
    "    \n",
    "    frame_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    mask = cv2.inRange(frame_hsv, (lb, lg, lr), (hb, hg, hr))\n",
    "    \n",
    "    mask_3ch = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    res = np.concatenate((frame, 255 - mask_3ch), axis=1)\n",
    "    \n",
    "    cv2.imshow(\"frame\", res)\n",
    "    #cv2.imshow(\"mask\", mask)\n",
    "\n",
    "    print(lb, lg, lr, hb, hg, hr)\n",
    "    \n",
    "    key = cv2.waitKey(240) & 0xFF\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    if (key == ord('q')):\n",
    "        print(lb, lg, lr, hb, hg, hr)\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db7cad4",
   "metadata": {},
   "source": [
    "## Часть 4: морфологическая обработка масок\n",
    "\n",
    "Ознакомьтесь с документацией по морфологическим операциям\n",
    "\n",
    "https://docs.opencv.org/3.4/d9/d61/tutorial_py_morphological_ops.html\n",
    "\n",
    "**Задание 12:** попробуйте применить эрозию, наращивание, открытие, закрытие. Обратите внимание на то, что происходит с шумом, с областями внутри маски при больших размерах ядра (около 50).\n",
    "\n",
    "**Задание 13:** попробуйте скомбинировать несколько морфологических операций, чтобы полностью убрать шум, но при этом маски объектов точно соответствовали объектам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a23ee5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def nothing(val):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow(\"frame\")\n",
    "\n",
    "cv2.createTrackbar(\"ksz\", \"frame\", 0, 50, nothing)\n",
    "\n",
    "img = cv2.imread(\"objects.jpg\")\n",
    "\n",
    "while(True):\n",
    "    frame_ = copy.deepcopy(img)\n",
    "    w, h, _ = frame_.shape\n",
    "    frame = cv2.resize(frame_, (h // 4, w // 4))\n",
    "    frame_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    mask = 255 - cv2.inRange(frame_hsv, (7, 14, 78), (25, 80, 185))\n",
    "    \n",
    "    #применение морфологических операций\n",
    "    ksz = cv2.getTrackbarPos(\"ksz\", \"frame\") + 1\n",
    "    kernel = np.ones((ksz, ksz), np.uint8)\n",
    "    #mask = cv2.erode(mask, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    mask_3ch = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    res = np.concatenate((frame, mask_3ch), axis=1)\n",
    "    \n",
    "    cv2.imshow(\"frame\", res)\n",
    "    \n",
    "    #out.write(res_resized)\n",
    "    \n",
    "    key = cv2.waitKey(240) & 0xFF\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    if (key == ord('q')):\n",
    "        break\n",
    "\n",
    "#out.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a8e02c",
   "metadata": {},
   "source": [
    "## Часть 5: фильтрация связных компонент\n",
    "\n",
    "Изучите первый ответ по этой ссылке\n",
    "\n",
    "https://stackoverflow.com/questions/35854197/how-to-use-opencvs-connectedcomponentswithstats-in-python\n",
    "\n",
    "**Задание 14:** добавьте в код фильтрацию объектов по площади.\n",
    "\n",
    "**Задание 15:** нарисуйте вокруг объектов, которые остаются после фильтрации, их bounding box-ы (ограничивающие прямоугольники).\n",
    "\n",
    "**Задание 16:** используя все изученные фильтры и все доступные характеристики областей маски (ширину, высоту и площадь), выделите по отдельности все объекты, то есть только первый, только второй и так далее. Это задание можно выполнять параллельно для разных объектов, например первая группа выделяет левые четыре объекта, а вторая правые четыре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9d07ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def nothing(val):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow(\"frame\")\n",
    "\n",
    "cv2.createTrackbar(\"area\", \"frame\", 0, 100, nothing)\n",
    "\n",
    "img = cv2.imread(\"objects.jpg\")\n",
    "\n",
    "while(True):\n",
    "    frame_ = copy.deepcopy(img)\n",
    "    w, h, _ = frame_.shape\n",
    "    frame = cv2.resize(frame_, (h // 4, w // 4))\n",
    "    frame_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    mask = 255 - cv2.inRange(frame_hsv, (7, 14, 78), (25, 80, 185))\n",
    "    \n",
    "    den_th = cv2.getTrackbarPos(\"area\", \"frame\") / 100.0\n",
    "    \n",
    "    #далее происходит обработка связных компонент\n",
    "    connectivity = 4\n",
    "    output = cv2.connectedComponentsWithStats(mask, connectivity, cv2.CV_32S)\n",
    "    num_labels = output[0]\n",
    "    labels = output[1]\n",
    "    stats = output[2]\n",
    "        \n",
    "    for i in range(1, num_labels):\n",
    "        #if (stats[i, cv2.CC_STAT_AREA] < th_area):\n",
    "        a = stats[i, cv2.CC_STAT_AREA]\n",
    "        w = stats[i, cv2.CC_STAT_WIDTH]\n",
    "        h = stats[i, cv2.CC_STAT_HEIGHT]\n",
    "        \n",
    "        density = a / (w * h)\n",
    "\n",
    "        if (density < den_th):\n",
    "            mask[np.where(labels == i)] = 0\n",
    "    \n",
    "    mask_3ch = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    res = np.concatenate((frame, mask_3ch), axis=1)\n",
    "    \n",
    "    cv2.imshow(\"frame\", res)\n",
    "    \n",
    "    key = cv2.waitKey(240) & 0xFF\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    if (key == ord('q')):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f8e8d9",
   "metadata": {},
   "source": [
    "## Часть 6: свободное плавание\n",
    "\n",
    "**Задание 17:** реализуйте программу, выделяющую лицо человека на кадрах с веб-камеры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29dfd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec592fef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
